{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOu0eWSmWmWqmFPMLQ9o4Do",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/azliyanaazahari/Project_DeepLearning/blob/main/BirdCLEF2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ¦ BirdCLEF 2025 KerasCV Starter\n",
        "# =======================================\n",
        "\n",
        "# ğŸ“¦ Install required libraries\n",
        "!pip install -q tensorflow keras-core keras-cv tensorflow-io librosa pyarrow fastparquet\n",
        "\n",
        "# ğŸ“š Import libraries\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # Reduce TensorFlow verbosity\n",
        "\n",
        "import keras\n",
        "import keras_cv\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa\n",
        "import librosa.display as lid\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import math\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QcmNc52EzBQ",
        "outputId": "fe291388-ea40-48fd-bbeb-c21852499eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m650.7/650.7 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
            "caused by: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl8str_util8EndsWithESt17basic_string_viewIcSt11char_traitsIcEES4_']\n",
            "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
            "/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
            "caused by: ['/usr/local/lib/python3.11/dist-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZN3tsl8str_util9LowercaseB5cxx11ESt17basic_string_viewIcSt11char_traitsIcEE']\n",
            "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# âœ… Configuration\n",
        "class CFG:\n",
        "    # General\n",
        "    seed = 42\n",
        "    batch_size = 32\n",
        "    epochs = 30\n",
        "\n",
        "    # Audio processing\n",
        "    duration = 15\n",
        "    sample_rate = 32000\n",
        "    audio_len = duration * sample_rate\n",
        "    resample_rate = 32000\n",
        "\n",
        "    # Spectrogram\n",
        "    img_size = [224, 224]\n",
        "    n_mels = 224\n",
        "    nfft = 2048\n",
        "    hop_length = 512\n",
        "    fmin = 50\n",
        "    fmax = 14000\n",
        "\n",
        "    # Model\n",
        "    preset = 'efficientnetv2_b2_imagenet'\n",
        "    dropout_rate = 0.2\n",
        "\n",
        "    # Augmentation\n",
        "    augment = True\n",
        "    mixup_alpha = 0.4\n",
        "    spec_augment = True\n",
        "\n",
        "    # Learning\n",
        "    initial_lr = 1e-4\n",
        "    min_lr = 1e-6\n",
        "    lr_patience = 3\n",
        "    early_stop_patience = 7"
      ],
      "metadata": {
        "id": "LX9hE-g_JhIR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# ğŸ¦ Instead of downloading from Kaggle, upload your ZIP files manually\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Upload birdclef-2025.zip:\")\n",
        "uploaded = files.upload()  # Upload your downloaded birdclef-2025.zip file here\n",
        "\n",
        "# Unzip the uploaded file\n",
        "!unzip -q birdclef-2025.zip -d birdclef2025\n",
        "!rm birdclef-2025.zip\n",
        "\n",
        "# ğŸ·ï¸ Now load the metadata\n",
        "BASE_PATH = '/content/birdclef2025'\n",
        "df = pd.read_csv(f'{BASE_PATH}/train_metadata.csv')\n",
        "\n",
        "# ğŸµ Unzip the train audio files (this might take time and space)\n",
        "!unzip -q '{BASE_PATH}/train_audio.zip' -d '{BASE_PATH}'\n",
        "\n",
        "# Update file paths in dataframe\n",
        "df['filepath'] = f'{BASE_PATH}/train_audio/' + df['filename']\n",
        "\n",
        "# Check if files exist (sample check)\n",
        "print(\"Verifying files exist...\")\n",
        "sample_files = df['filepath'].sample(3).values\n",
        "for file in sample_files:\n",
        "    print(f\"{file} - {'Exists' if os.path.exists(file) else 'Missing'}\")\n",
        "\n",
        "# Prepare class mappings\n",
        "class_names = sorted(df.primary_label.unique())\n",
        "\n",
        "class CFG:\n",
        "    seed = 42\n",
        "    class_names = class_names\n",
        "    num_classes = len(class_names)\n",
        "    name2label = {v: k for k, v in enumerate(class_names)}\n",
        "\n",
        "df['target'] = df.primary_label.map(CFG.name2label)\n",
        "\n",
        "# Class weights for imbalance\n",
        "class_counts = df.primary_label.value_counts()\n",
        "median_count = class_counts.median()\n",
        "CFG.class_weights = {i: median_count/count for i, count in enumerate(class_counts)}\n",
        "\n",
        "# Train/validation split\n",
        "train_df, valid_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df['primary_label'],\n",
        "    random_state=CFG.seed\n",
        ")\n",
        "\n",
        "print(f\"\\nâœ… Data loaded successfully! {len(df)} samples, {CFG.num_classes} classes\")\n",
        "print(f\"  Training samples: {len(train_df)}\")\n",
        "print(f\"  Validation samples: {len(valid_df)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "mnw1wxAvJmdx",
        "outputId": "08a5711e-c431-422f-dd37-1053c915123a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload birdclef-2025.zip:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-42a9d7aa-2c09-4961-a330-452f0466d226\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-42a9d7aa-2c09-4961-a330-452f0466d226\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-fbcd633b8b1f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Upload birdclef-2025.zip:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Upload your downloaded birdclef-2025.zip file here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Unzip the uploaded file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m(target_dir)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \"\"\"\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m   \u001b[0;32mwhile\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'complete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     result = _output.eval_js(\n\u001b[0m\u001b[1;32m    173\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[1;32m    174\u001b[0m             \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ”Š Audio processing functions\n",
        "def build_decoder(with_labels=True, target_len=CFG.audio_len):\n",
        "    def get_audio(filepath):\n",
        "        file_bytes = tf.io.read_file(filepath)\n",
        "        audio = tfio.audio.decode_vorbis(file_bytes)\n",
        "        audio = tf.cast(audio, tf.float32)\n",
        "        if tf.shape(audio)[-1] > 1:\n",
        "            audio = tf.reduce_mean(audio, axis=-1)\n",
        "        if CFG.sample_rate != CFG.resample_rate:\n",
        "            audio = tfio.audio.resample(\n",
        "                audio,\n",
        "                rate_in=CFG.sample_rate,\n",
        "                rate_out=CFG.resample_rate\n",
        "            )\n",
        "        return audio\n",
        "\n",
        "    def crop_or_pad(audio, target_len):\n",
        "        audio_len = tf.shape(audio)[0]\n",
        "        diff_len = tf.abs(target_len - audio_len)\n",
        "        if audio_len < target_len:\n",
        "            pad1 = tf.random.uniform([], maxval=diff_len, dtype=tf.int32)\n",
        "            pad2 = diff_len - pad1\n",
        "            audio = tf.pad(audio, paddings=[[pad1, pad2]])\n",
        "        elif audio_len > target_len:\n",
        "            idx = tf.random.uniform([], maxval=diff_len, dtype=tf.int32)\n",
        "            audio = audio[idx : idx + target_len]\n",
        "        return tf.reshape(audio, [target_len])\n",
        "\n",
        "    def log_mel_spectrogram(audio):\n",
        "        stfts = tf.signal.stft(\n",
        "            audio,\n",
        "            frame_length=CFG.nfft,\n",
        "            frame_step=CFG.hop_length,\n",
        "            fft_length=CFG.nfft\n",
        "        )\n",
        "        spectrograms = tf.abs(stfts)\n",
        "        num_spectrogram_bins = stfts.shape[-1]\n",
        "        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "            CFG.n_mels,\n",
        "            num_spectrogram_bins,\n",
        "            CFG.resample_rate,\n",
        "            CFG.fmin,\n",
        "            CFG.fmax\n",
        "        )\n",
        "        mel_spectrograms = tf.tensordot(\n",
        "            spectrograms,\n",
        "            linear_to_mel_weight_matrix,\n",
        "            1\n",
        "        )\n",
        "        mel_spectrograms.set_shape(spectrograms.shape[:-1] + [CFG.n_mels])\n",
        "        return tf.math.log(mel_spectrograms + 1e-6)\n",
        "\n",
        "    def decode(path):\n",
        "        audio = get_audio(path)\n",
        "        audio = crop_or_pad(audio, target_len)\n",
        "        spec = log_mel_spectrogram(audio)\n",
        "        spec = tf.tile(spec[..., tf.newaxis], [1, 1, 3])\n",
        "        return tf.image.resize(spec, CFG.img_size)\n",
        "\n",
        "    def get_target(label):\n",
        "        return tf.one_hot(tf.cast(label, tf.int32), CFG.num_classes)\n",
        "\n",
        "    return lambda path, label: (decode(path), get_target(label)) if with_labels else decode"
      ],
      "metadata": {
        "id": "kUB6c9JgJrEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ” Augmentation\n",
        "def build_augmenter():\n",
        "    augmenters = []\n",
        "    if CFG.augment:\n",
        "        if CFG.mixup_alpha > 0:\n",
        "            augmenters.append(keras_cv.layers.MixUp(alpha=CFG.mixup_alpha))\n",
        "        if CFG.spec_augment:\n",
        "            augmenters.extend([\n",
        "                keras_cv.layers.RandomCutout(height_factor=(0.0, 0.1), width_factor=(0.0, 0.2)),\n",
        "                keras_cv.layers.RandomCutout(height_factor=(0.0, 0.2), width_factor=(0.0, 0.1))\n",
        "            ])\n",
        "\n",
        "    def augment(img, label):\n",
        "        if not augmenters:\n",
        "            return img, label\n",
        "        data = {\"images\": img, \"labels\": label}\n",
        "        for augmenter in augmenters:\n",
        "            if tf.random.uniform([]) < 0.5:\n",
        "                data = augmenter(data, training=True)\n",
        "        return data[\"images\"], data[\"labels\"]\n",
        "    return augment\n"
      ],
      "metadata": {
        "id": "A-Dwx93XJvkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“¦ Dataset builder\n",
        "def build_dataset(paths, labels=None, batch_size=32, shuffle=True, augment=False, repeat=False):\n",
        "    decode_fn = build_decoder(with_labels=labels is not None)\n",
        "    augment_fn = build_augmenter()\n",
        "\n",
        "    ds = tf.data.Dataset.from_tensor_slices((paths,) if labels is None else (paths, labels))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(8 * batch_size, seed=CFG.seed)\n",
        "    ds = ds.map(decode_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if repeat:\n",
        "        ds = ds.repeat()\n",
        "    ds = ds.batch(batch_size)\n",
        "    if augment:\n",
        "        ds = ds.map(augment_fn, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    return ds.prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "nSfxcQjOJ0TB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ§  Model architecture\n",
        "def build_model():\n",
        "    inp = keras.Input(shape=(*CFG.img_size, 3))\n",
        "    backbone = keras_cv.models.EfficientNetV2Backbone.from_preset(CFG.preset, include_rescaling=True)\n",
        "    x = backbone(inp)\n",
        "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
        "    x = keras.layers.Dropout(CFG.dropout_rate)(x)\n",
        "    x = keras.layers.Dense(512, activation='swish')(x)\n",
        "    x = keras.layers.Dropout(CFG.dropout_rate)(x)\n",
        "    out = keras.layers.Dense(CFG.num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(inputs=inp, outputs=out)\n",
        "    optimizer = keras.optimizers.AdamW(learning_rate=CFG.initial_lr, weight_decay=1e-4)\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\", keras.metrics.TopKCategoricalAccuracy(k=5, name='top5_accuracy')]\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "bUsfwwkcJ4U1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸš€ Training setup\n",
        "def lr_schedule(epoch):\n",
        "    warmup_epochs = 5\n",
        "    if epoch < warmup_epochs:\n",
        "        return CFG.initial_lr * (epoch + 1) / warmup_epochs\n",
        "    progress = (epoch - warmup_epochs) / (CFG.epochs - warmup_epochs)\n",
        "    return CFG.min_lr + 0.5 * (CFG.initial_lr - CFG.min_lr) * (1 + math.cos(math.pi * progress))\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.LearningRateScheduler(lr_schedule),\n",
        "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=CFG.lr_patience, verbose=1, min_lr=CFG.min_lr),\n",
        "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=CFG.early_stop_patience, restore_best_weights=True, verbose=1),\n",
        "    keras.callbacks.ModelCheckpoint(\"best_model.keras\", monitor='val_accuracy', save_best_only=True, mode='max'),\n",
        "    keras.callbacks.CSVLogger('training_log.csv')\n",
        "]"
      ],
      "metadata": {
        "id": "Y4-j0_JhJ7nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ‹ï¸ Training\n",
        "model = build_model()\n",
        "model.summary()\n",
        "\n",
        "train_ds = build_dataset(\n",
        "    train_df.filepath.values,\n",
        "    train_df.target.values,\n",
        "    batch_size=CFG.batch_size,\n",
        "    augment=CFG.augment,\n",
        "    repeat=True\n",
        ")\n",
        "\n",
        "valid_ds = build_dataset(\n",
        "    valid_df.filepath.values,\n",
        "    valid_df.target.values,\n",
        "    batch_size=CFG.batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=valid_ds,\n",
        "    epochs=CFG.epochs,\n",
        "    steps_per_epoch=len(train_df) // CFG.batch_size,\n",
        "    callbacks=callbacks,\n",
        "    class_weight=CFG.class_weights\n",
        ")"
      ],
      "metadata": {
        "id": "xEnI5qMwJ-Zp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ’¾ Save model\n",
        "model.save('final_model.keras')\n"
      ],
      "metadata": {
        "id": "4ruUmzQzKBaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ğŸ“Š Visualization\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "    plt.title('Accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train')\n",
        "    plt.plot(history.history['val_loss'], label='Validation')\n",
        "    plt.title('Loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "print(\"âœ… Training complete!\")"
      ],
      "metadata": {
        "id": "Pr1gnBBqKEJT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}